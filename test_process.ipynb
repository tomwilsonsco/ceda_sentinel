{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import lxml\n",
    "from datetime import datetime, timedelta\n",
    "from shapely.geometry import box\n",
    "from fiona.drvsupport import supported_drivers\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input a date range and a polygon for area(s) of interest\n",
    "- Find folders that are within that date range\n",
    "- Find images that intersect the polygons\n",
    "- Clip the images that intersect by the polygons and save geotiff of the interecting area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://data.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2023-05-01\"\n",
    "end_date = \"2023-05-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sentinel2_tiles(aoi, tiles_layer=None):\n",
    "    if tiles_layer is None:\n",
    "        supported_drivers[\"KML\"] = \"rw\"\n",
    "        tiles_layer = gpd.read_file(\n",
    "            \"https://sentinels.copernicus.eu/documents/247904/1955685/S2A_OPER_GIP_TILPAR_MPC__20151209T095117_V20150622T000000_21000101T000000_B00.kml\",\n",
    "            driver=\"kml\",\n",
    "        )\n",
    "    tile_list = gpd.sjoin(\n",
    "        tiles_layer, aoi.to_crs(epsg=4326), how=\"inner\", op=\"intersects\"\n",
    "    )[\"Name\"].to_list()\n",
    "    return [f\"T{t}\" for t in tile_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eidf072/eidf072/tomwilson-eidf072/.conda/envs/geospatial/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3548: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "aoi = gpd.read_file(\"inputs/test_quarries.shp\")\n",
    "tile_list = filter_sentinel2_tiles(aoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_url(base_url, input_date):\n",
    "    year = input_date.strftime(\"%Y\")\n",
    "    month = input_date.strftime(\"%m\")\n",
    "    day = input_date.strftime(\"%d\")\n",
    "    return f\"{base_url}/{year}/{month}/{day}\"\n",
    "\n",
    "\n",
    "def get_existing_folders(base_url, start_date, end_date):\n",
    "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    current_date = start_date\n",
    "    urls = []\n",
    "    while current_date <= end_date:\n",
    "        check_url = create_date_url(base_url, current_date)\n",
    "        response = requests.get(check_url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            urls.append(check_url)\n",
    "        current_date += timedelta(days=1)\n",
    "    return urls\n",
    "\n",
    "\n",
    "def extract_xml_links(url, tile_list=None):\n",
    "    \"\"\"Extracts XML links from the given HTML webpage URL.\"\"\"\n",
    "    xml_links = []\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        for link in soup.find_all(\"a\", href=True):\n",
    "            href = link[\"href\"]\n",
    "            if href.endswith(\".xml?download=1\"):\n",
    "                if isinstance(tile_list, list):\n",
    "                    for t in tile_list:\n",
    "                        if t in href:\n",
    "                            xml_links.append(href)\n",
    "                else:\n",
    "                    xml_links.append\n",
    "\n",
    "    return xml_links\n",
    "\n",
    "\n",
    "def all_xml_list(base_url, start_date, end_date, tile_list=None):\n",
    "    date_urls = get_existing_folders(base_url, start_date, end_date)\n",
    "    xml_links = []\n",
    "    for url in date_urls:\n",
    "        xml_links.extend(extract_xml_links(url, tile_list))\n",
    "    return xml_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/05/02/S2B_20230502_latn563lonw0021_T30VWH_ORB080_20230502121918_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_meta.xml?download=1',\n",
       " 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/05/02/S2B_20230502_latn563lonw0021_T30VWH_ORB080_20230502121918_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_meta.xml?download=1']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_links = all_xml_list(base_url, start_date, end_date, tile_list)\n",
    "print(len(xml_links))\n",
    "xml_links[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_xml_cloud(xml_extract):\n",
    "    supp = xml_extract.find(\"gmd:supplementalinformation\")\n",
    "    character_string = supp.find(\"gco:characterstring\").text\n",
    "    lines = character_string.split(\"\\n\")\n",
    "    lines = [\"\".join(l.split()) for l in lines]\n",
    "    for line in lines:\n",
    "        if line.startswith(\"ARCSI_CLOUD_COVER\"):\n",
    "            arcsi_cloud_cover = line.split(\":\")[1].strip()\n",
    "            val = arcsi_cloud_cover\n",
    "            break\n",
    "    return float(val)\n",
    "\n",
    "\n",
    "def _clean_coord(coord):\n",
    "    coord = coord.replace(\"\\n\", \"\")\n",
    "    return float(coord)\n",
    "\n",
    "\n",
    "def _extract_extent(xml_extract):\n",
    "    minx = _clean_coord(xml_extract.find(\"gmd:westboundlongitude\").text)\n",
    "    miny = _clean_coord(xml_extract.find(\"gmd:southboundlatitude\").text)\n",
    "    maxx = _clean_coord(xml_extract.find(\"gmd:eastboundlongitude\").text)\n",
    "    maxy = _clean_coord(xml_extract.find(\"gmd:northboundlatitude\").text)\n",
    "    return minx, miny, maxy, maxy\n",
    "\n",
    "\n",
    "def _read_xml(url):\n",
    "    # Send an HTTP GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the XML content using BeautifulSoup with lxml parser\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    return soup\n",
    "\n",
    "\n",
    "def filter_xmls(xml_links, southern_most_lat=54, geometry=None, cloud_cover_max=0.4):\n",
    "    retained_links = []\n",
    "    for url in xml_links:\n",
    "        # read the xml\n",
    "        try:\n",
    "            xml_extract = _read_xml(url)\n",
    "        except:\n",
    "            continue\n",
    "        # first get the coords and see if image is too far south\n",
    "        coords = _extract_extent(xml_extract)\n",
    "        if coords[3] < southern_most_lat:\n",
    "            continue\n",
    "        # check if too cloudy overall\n",
    "        if _extract_xml_cloud(xml_extract) > cloud_cover_max:\n",
    "            continue\n",
    "        # finally if specified check extent intersects input geometry\n",
    "        if geometry is not None:\n",
    "            image_geom = box(coords)\n",
    "            if image_geom.intersects(geometry):\n",
    "                retained_links.append(url)\n",
    "        else:\n",
    "            retained_links.append(url)\n",
    "    return retained_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_xml_links = filter_xmls(xml_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_xml_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_tif_link(xml_link):\n",
    "    return xml_link.replace(\"_meta.xml?download=1\", \".tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = xml_to_tif_link(filtered_xml_links[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driver': 'GTiff', 'dtype': 'uint16', 'nodata': 0.0, 'width': 11139, 'height': 11140, 'count': 10, 'crs': CRS.from_epsg(27700), 'transform': Affine(10.0, 0.0, 438940.0,\n",
      "       0.0, -10.0, 871480.0), 'blockxsize': 512, 'blockysize': 512, 'tiled': True, 'compress': 'deflate', 'interleave': 'pixel'}\n",
      "BoundingBox(left=438940.0, bottom=760080.0, right=550330.0, top=871480.0)\n"
     ]
    }
   ],
   "source": [
    "import rasterio as rio\n",
    "\n",
    "with rio.open(test_url) as f:\n",
    "    print(f.profile)\n",
    "    print(f.bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "supported_drivers[\"KML\"] = \"rw\"\n",
    "grids = gpd.read_file(\n",
    "    \"https://sentinels.copernicus.eu/documents/247904/1955685/S2A_OPER_GIP_TILPAR_MPC__20151209T095117_V20150622T000000_21000101T000000_B00.kml\",\n",
    "    driver=\"kml\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = gpd.read_file(\"inputs/test_quarries.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Projected CRS: EPSG:27700>\n",
       "Name: OSGB36 / British National Grid\n",
       "Axis Info [cartesian]:\n",
       "- E[east]: Easting (metre)\n",
       "- N[north]: Northing (metre)\n",
       "Area of Use:\n",
       "- name: United Kingdom (UK) - offshore to boundary of UKCS within 49째45'N to 61째N and 9째W to 2째E; onshore Great Britain (England, Wales and Scotland). Isle of Man onshore.\n",
       "- bounds: (-9.01, 49.75, 2.01, 61.01)\n",
       "Coordinate Operation:\n",
       "- name: British National Grid\n",
       "- method: Transverse Mercator\n",
       "Datum: Ordnance Survey of Great Britain 1936\n",
       "- Ellipsoid: Airy 1830\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoi.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eidf072/eidf072/tomwilson-eidf072/.conda/envs/geospatial/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3488: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['30UWG', '30VWH', '30VUH', '30VVH', '30VWH', '30VVK']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpd.sjoin(grids, aoi.to_crs(epsg=4326), how=\"inner\", op=\"intersects\")[\"Name\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'contains'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mst\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'contains'"
     ]
    }
   ],
   "source": [
    "\"test\".contains(\"st\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
